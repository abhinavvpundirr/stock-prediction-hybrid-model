# Model parameters
lstm:
  lookback_days: 60
  epochs: 100
  batch_size: 32
  layers:
    - units: 50
      dropout: 0.2
    - units: 50
      dropout: 0.2
    - units: 50
      dropout: 0.2

llm:
  model_name: "google/flan-t5-base"
  max_length: 100

hybrid:
  lstm_weight: 0.6
  llm_weight: 0.4

# Data parameters
data:
  period: "1y"
  train_test_split: 0.8

# Prediction parameters
prediction:
  days_to_predict: 10

